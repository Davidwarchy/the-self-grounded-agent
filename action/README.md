The idea is that we can try and move towards a specific object in the environment. 

There's levels here 

- Fixed initial agent position; fixed reward position 
- Random initial agent position; fixed reward 
- Fixed initial agent position; random reward position 
- No knowledge of reward (ie, we aren't optimizing for reward - we can be optimizing for some random internal/external state or simply use another paradigm for action that isn't RL)