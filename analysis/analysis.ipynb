{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63f52b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to: c:\\Users\\HP\\Desktop\\Projects\\navigation\\9-daniel-cremers-random-motion-collect\n",
      "Success: 'analysis/' directory is ready!\n"
     ]
    }
   ],
   "source": [
    "# AUTO-SET PROJECT ROOT (contains 'analysis/') – ONE CELL, NO FILES CREATED\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Start from current directory\n",
    "current = Path.cwd()\n",
    "original = current\n",
    "\n",
    "# Walk up until we find a folder that has 'analysis' as a subfolder\n",
    "while current != current.parent:  # stop at filesystem root\n",
    "    if (current / \"analysis\").is_dir():\n",
    "        break\n",
    "    current = current.parent\n",
    "else:\n",
    "    # If not found, stay where we are and warn\n",
    "    print(\"Warning: 'analysis/' folder not found in any parent. Staying in:\", original)\n",
    "    current = original\n",
    "\n",
    "# Change to the root (the folder *containing* analysis/)\n",
    "os.chdir(current)\n",
    "print(f\"Working directory set to: {os.getcwd()}\")\n",
    "\n",
    "# Optional: quick sanity check\n",
    "if (Path.cwd() / \"analysis\").is_dir():\n",
    "    print(\"Success: 'analysis/' directory is ready!\")\n",
    "else:\n",
    "    print(\"Warning: Still no 'analysis/' folder. You may need to create it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "208c9abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using map image: environments\\images\\6.png\n",
      "[INFO] Loading output/2025-11-14-213949_random_walk_10k/merged_100.parquet ...\n",
      "[INFO] Total columns: 105\n",
      "[INFO] Loaded embeddings: (9998, 64)\n",
      "\n",
      "=== ARRAY LENGTHS AFTER ALIGNMENT ===\n",
      "              x: 9998\n",
      "              y: 9998\n",
      "          theta: 9998\n",
      "   dist_to_wall: 9998\n",
      "       openness: 9998\n",
      " turn_intensity: 9998\n",
      "     embeddings: 9998\n",
      "            rgb: 9998\n",
      "[INFO] Map overlay added: environments\\images\\6.png\n",
      "[INFO] Saved to output/2025-11-14-213949_random_walk_10k/train_2025-11-14-215407/analysis_images\\1_all_embeddings.pdf\n",
      "[INFO] Saved to output/2025-11-14-213949_random_walk_10k/train_2025-11-14-215407/analysis_images\\2_oriented_180.pdf\n",
      "[INFO] Saved to output/2025-11-14-213949_random_walk_10k/train_2025-11-14-215407/analysis_images\\3_random_cluster.pdf\n",
      "[INFO] Saved to output/2025-11-14-213949_random_walk_10k/train_2025-11-14-215407/analysis_images\\4_correlations.pdf\n",
      "\n",
      "All analysis complete! Check: output/2025-11-14-213949_random_walk_10k/train_2025-11-14-215407/analysis_images\n"
     ]
    }
   ],
   "source": [
    "# analysis/run_analysis.py\n",
    "import os\n",
    "import numpy as np\n",
    "from analysis import (\n",
    "    load_parquet, load_embeddings, prepare_data, compute_pca_rgb,\n",
    "    compute_features, align_arrays, plot_embeddings_on_map,\n",
    "    plot_oriented_embeddings, plot_random_cluster, plot_correlations,\n",
    "    get_map_image_path\n",
    ")\n",
    "\n",
    "# ================== CONFIG ==================\n",
    "DATA_OUTPUT_DIR = \"output/2025-11-14-213949_random_walk_10k\"\n",
    "PARQUET_PATH = f\"{DATA_OUTPUT_DIR}/merged_100.parquet\"\n",
    "TRAIN_DIR = \"train_2025-11-14-215407\"\n",
    "EMBEDDINGS_PATH = f\"{DATA_OUTPUT_DIR}/{TRAIN_DIR}/final_embeddings.npy\"\n",
    "SAVE_DIR = f\"{DATA_OUTPUT_DIR}/{TRAIN_DIR}/analysis_images\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ================== GET MAP IMAGE ==================\n",
    "map_image_path = get_map_image_path(DATA_OUTPUT_DIR)\n",
    "print(f\"[INFO] Using map image: {map_image_path}\")\n",
    "\n",
    "# ================== LOAD & PREPARE ==================\n",
    "df = load_parquet(PARQUET_PATH)\n",
    "embeddings = load_embeddings(EMBEDDINGS_PATH)\n",
    "\n",
    "# 1. Bring df and embeddings to the same length\n",
    "x, y, theta, lidar_data = prepare_data(df, embeddings)\n",
    "\n",
    "# 2. PCA → RGB (still matches embeddings length)\n",
    "rgb = compute_pca_rgb(embeddings)\n",
    "\n",
    "# 3. Hand-crafted features\n",
    "dist_to_wall, openness, turn_intensity = compute_features(lidar_data, theta)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. ALIGN *EVERY* array that will ever be indexed together\n",
    "# ------------------------------------------------------------------\n",
    "arrays_to_align = (\n",
    "    x, y, theta,               # pose\n",
    "    dist_to_wall, openness, turn_intensity,   # features\n",
    "    embeddings, rgb          # learned representation\n",
    ")\n",
    "\n",
    "aligned = align_arrays(*arrays_to_align)\n",
    "\n",
    "x, y, theta, dist_to_wall, openness, turn_intensity, embeddings, rgb = aligned\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5. DEBUG: print lengths (you will see them all equal)\n",
    "# ------------------------------------------------------------------\n",
    "print(\"\\n=== ARRAY LENGTHS AFTER ALIGNMENT ===\")\n",
    "for name, arr in [\n",
    "    (\"x\", x), (\"y\", y), (\"theta\", theta),\n",
    "    (\"dist_to_wall\", dist_to_wall), (\"openness\", openness), (\"turn_intensity\", turn_intensity),\n",
    "    (\"embeddings\", embeddings), (\"rgb\", rgb),\n",
    "]:\n",
    "    print(f\"{name:>15}: {len(arr)}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6. OPTIONAL: sanity-check that we really have the same length\n",
    "# ------------------------------------------------------------------\n",
    "assert len({len(a) for a in aligned}) == 1, \"Not all arrays have the same length!\"\n",
    "\n",
    "# ================== PLOTS ==================\n",
    "max_points = 100_000          # feel free to lower for faster previews\n",
    "\n",
    "# 1. All embeddings\n",
    "plot_embeddings_on_map(\n",
    "    x, y, rgb,\n",
    "    map_image_path=map_image_path,\n",
    "    max_points=max_points,\n",
    "    save_path=os.path.join(SAVE_DIR, \"1_all_embeddings.pdf\")\n",
    ")\n",
    "\n",
    "# 2. Oriented subset (180° ±10°)\n",
    "plot_oriented_embeddings(\n",
    "    x, y, theta, rgb,\n",
    "    map_image_path=map_image_path,\n",
    "    target_orientation=180, tolerance=10,\n",
    "    save_path=os.path.join(SAVE_DIR, \"2_oriented_180.pdf\")\n",
    ")\n",
    "\n",
    "# 3. Random K-means cluster\n",
    "plot_random_cluster(\n",
    "    x, y, embeddings,\n",
    "    map_image_path=map_image_path,\n",
    "    n_clusters=50,\n",
    "    save_path=os.path.join(SAVE_DIR, \"3_random_cluster.pdf\")\n",
    ")\n",
    "\n",
    "# 4. Correlation bar-charts\n",
    "features = {\n",
    "    \"Distance to Wall\": dist_to_wall,\n",
    "    \"Openness\": openness\n",
    "}\n",
    "plot_correlations(\n",
    "    features, rgb,\n",
    "    save_path=os.path.join(SAVE_DIR, \"4_correlations.pdf\")\n",
    ")\n",
    "\n",
    "print(\"\\nAll analysis complete! Check:\", SAVE_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
